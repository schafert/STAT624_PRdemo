{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c591d3ad",
   "metadata": {},
   "source": [
    "# Group Assignment: Data Preparation and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a4ff4",
   "metadata": {},
   "source": [
    "## 1. Group members\n",
    "\n",
    "Venus Pondevida, Emanuela Ene, Gideon Jayanth, Rishabh Vishnuraj Prasad\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e65dfa",
   "metadata": {},
   "source": [
    "## 2. Contribution report\n",
    "\n",
    "After completing the assignment, please answer the following questions **as a group** by adding your answers within this markdown block.\n",
    "\n",
    "1. In a few sentences, describe each group member's individual contributions to the submission. Be as specific as possible (e.g. coordinated group efforts, specific problems answered, specific problems reviewed/revised, sections of the submission written, etc.).\n",
    "\n",
    " Emanuela Ene: I have investigated the history of the ZoomZoom business, for both production and sales point of view, and have compared the average sale price and the cummulative sales per product_type.
	I have coded the Part 3. I have identified the proper scale and color palette such that all plots in the team's report will communicate a consistent message, emphasizing the dichotomy autos vs. scooters. 
	I have collaborated with the other team members, learning from them or sharing with them my findings.\n",
    "\n",
    "\n",
    "2. In a few sentences, describe what was learned in completing this assignment. In particular, describe what was learned through the **specific individual contributions** mentioned above.\n",
    "    \n",
    "  Emanuela Ene: I learned how to verify the integrity of the database via output crossvalidation with the team members, 
	how to change the scale on x- and y- axes in seaborn, how to set facet orientation on rows and columns inseaborn,
	how to simplify the queries in python, how to add or subtract plots in python, and how to edit in markdown via notepad++. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eadb26",
   "metadata": {},
   "source": [
    "## 3. Assignment\n",
    "\n",
    "### Instructions: \n",
    "You will be presented with a scenario and will need to utilize your SQL and python skills to complete this assignment successfully. \n",
    "\n",
    "Put this .ipynb file in the `jupyter_notebooks` folder in your Docker SQLPython Container directory.  Then you will be able to connect to the database and run your code without issue.\n",
    "\n",
    "Each group will submit two files:\n",
    "1. A single Jupyter Notebook (.ipynb).  **You must run all cells before submitting.** This notebook should have all of the relevant visualizations and output displayed properly.  We will restart and run all of the code from this notebook, which should not produce any errors.\n",
    "2. A PDF version (.pdf) of the Jupyter Notebook. This PDF should have all of the relevant visualizations and output displayed properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de42dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://{username}:{pswd}@{host}:{port}/{database}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, None, 'Arlena', 'Riveles', None, 'ariveles0@stumbleupon.com', 'F', '98.36.172.246', None, None, None, None, None, None, None, datetime.datetime(2017, 4, 23, 0, 0)),\n",
       " (2, 'Dr', 'Ode', 'Stovin', None, 'ostovin1@npr.org', 'M', '16.97.59.186', '314-534-4361', '2573 Fordem Parkway', 'Saint Louis', 'MO', '63116', 38.5814, -90.2625, datetime.datetime(2014, 10, 2, 0, 0))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this code first to connect to the database and verify the connection is working\n",
    "## DO NOT MODIFY THIS CODE BLOCK\n",
    "## If you have placed this notebook in the jupyter notebooks folder properly, \n",
    "## this block should return the first two rows of the customers table\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cnxn_string = (\"postgresql+psycopg2://{username}:{pswd}\"\n",
    "              \"@{host}:{port}/{database}\")\n",
    "print(cnxn_string)\n",
    "\n",
    "engine = create_engine(cnxn_string.format(\n",
    "    username=\"postgres\",\n",
    "    pswd=\"behappy\",\n",
    "    host=\"postgres\",\n",
    "    port=5432,\n",
    "    database=\"sqlda\"))\n",
    "\n",
    "engine.execute(\"SELECT * FROM customers LIMIT 2;\").fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3ef9e",
   "metadata": {},
   "source": [
    "## Scenario \n",
    "\n",
    "You are a team of extremely successful data scientists at a top motor dealership company, ZoomZoom. You need to create summary tables and visualizations that your boss will present at the next company shareholder meeting.  She has sent you the following e-mail describing what she needs.\n",
    "\n",
    "***\n",
    "From: importantboss@zoomzoom.com\n",
    "\n",
    "To: datascienceteam@zoomzoom.com\n",
    "\n",
    "Subject: Data request for shareholder meeting\n",
    "\n",
    "For our next shareholder meeting, we need to provide more information about sales performance across product lines.  Please send me information to address the following items for our next shareholder meeting along with your thoughts.\n",
    "\n",
    "1. Popularity of products (4 most popular and 4 least popular)\n",
    "2. Across all products, how are they trending?\n",
    "3. How well are we meeting our weekly sales targets for scooters? for automobiles?\n",
    "\n",
    "Thank you!\n",
    "\n",
    "-Important Boss\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a35e92",
   "metadata": {},
   "source": [
    "Your team promptly comes up with the following plan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa35b6",
   "metadata": {},
   "source": [
    "## Part 1: Visualizing the popularity of products\n",
    "\n",
    "1. Write a SELECT query that returns the total unit sales for each product model from January 1, 2016 to now.  The table should have two columns, `model` and `total_unit_sales`, with one row for each model ordered by `total_unit_sales` in *descending* order. \n",
    "\n",
    "\n",
    "2. Use SQLAlchemy to execute the query and store the results in a pandas dataframe called `sales_by_model`.\n",
    "\n",
    "\n",
    "3. Display the rows in `sales_by_model` corresponding to the 4 most popular products based on unit sales in *descending* order.\n",
    "\n",
    "\n",
    "4. Display the rows in `sales_by_model` corresponding to the 4 least popular products based on unit sales in *ascending* order.\n",
    "\n",
    "\n",
    "5. Visualize unit sales by product model for the most and least popular products discovered in 1.3 and 1.4.  You can use more than one visualization.  These should be **presentation ready** (e.g. appropriate and complete titles and axis labels, remove unnecessary/distracting features, display date range for total unit sales, no overlapping axis labels, etc.). \n",
    "\n",
    "Include the code needed for each component of part 1 in the appropriate code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342643df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81539240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257adc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 display 4 most popular models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85cfd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.4 display 4 least popular models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e37aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.5 visualize most and least popular models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe237a7",
   "metadata": {},
   "source": [
    "## Part 2: Visualizing product line trends\n",
    "\n",
    "Create a table and visualization of historical cumulative sales amounts by product model. \n",
    "\n",
    "To do this, perform the following steps:\n",
    "\n",
    "1. Write a SELECT query that returns the cumulative total sales amount for each product model from January 1, 2016 to now.  The table should have five columns, `product_id`, `model`, `product_type`, `sales_transaction_date`, and `cumulative_sales`. `cumulative_sales` represents the cumulative sales amount from January 1, 2016 to the `sales_transaction_date` for products identified by `model`.  There should be a row for each distinct combination of `model` and `sales_transaction_date` in the `sales` table (*hint*: window function)\n",
    "\n",
    "\n",
    "2. Use SQLAlchemy to execute the query and store the results in a pandas dataframe called `cumulative_sales_byproduct`.\n",
    "    \n",
    "    \n",
    "3. Appropriately visualize historical cumulative sales by product across sales transaction dates separately for product types *in a single plot* (*hint*: seaborn). Visualization should be **presentation ready** (e.g. appropriate and complete titles and legend/axis labels, remove unnecessary/distracting features, display date range for total sales, no overlapping axis labels, integer-valued dealership IDs, states indicated clearly, variable names like `sales_transaction_date` and `product_type` are replaced with appropriate text like 'Date' and 'Type', etc.). \n",
    "\n",
    "Include the code needed for each component of part 1 in the appropriate code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7eef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e9be9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e9a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3df305",
   "metadata": {},
   "source": [
    "## Part 3: Weekly sales targets\n",
    "\n",
    "We define the target sales of a week as the average of the sales over the preceding 3 weeks. Create a table and visualization of weekly sales amounts and target sales by product type from January 1, 2016 to now.  \n",
    "\n",
    "To do this, perform the following steps:\n",
    "    \n",
    "   1. Write a SELECT query that returns three columns: `product_type`,`sales_transaction_week`, `weekly_sales`, and `weekly_target`.  `weekly_sales` represents the total sales amount for the week of `sales_transaction_date` for product type identified by `product_type`.  There should be a row for each distinct combination of `product_type` and `sales_transaction_week` in the `sales` table. Additionally, `weekly_target` is the average of the 3 preceding `weekly_sales` values not including the current week (*hint*: window frames).\n",
    "    \n",
    "    \n",
    "   2. Use SQLAlchemy to execute the query and store the results in a pandas dataframe called `product_weekly_sales`.\n",
    "    \n",
    "    \n",
    "   3. Appropriately visualize weekly sales and weekly target over time *in a single plot* by product type. In other words, there should be one visualization for scooters and one for automobiles. It is then your choice whether those visualizations are subplots or independent. Visualization should be **presentation ready** (e.g. appropriate and complete titles and legend/axis labels, remove unnecessary/distracting features, display date range for total sales, no overlapping axis labels, integer-valued dealership IDs, states indicated clearly, variable names like `sales_transaction_date` and `product_type` are replaced with appropriate text like 'Date' and 'Type', etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9631e826",
   "metadata": {},
   "source": [
    "**Hint**: In order to get the week from a date, we can use the transformation function, `DATE_TRUNC`. An example query is provided in the next code block and the help page can be found here: https://www.postgresql.org/docs/current/functions-datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81352181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_transaction_date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-19 08:38:41</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-14 09:59:02</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20 10:40:11</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-09 14:20:04</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-21 20:03:21</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-06-14 11:37:10</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-06-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-26 09:25:19</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-11-15 01:28:23</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-11-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-06-25 22:53:37</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-06-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-13 08:28:44</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2019-01-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sales_transaction_date       month        year        week\n",
       "0    2017-07-19 08:38:41  2017-07-01  2017-01-01  2017-07-17\n",
       "1    2017-08-14 09:59:02  2017-08-01  2017-01-01  2017-08-14\n",
       "2    2019-01-20 10:40:11  2019-01-01  2019-01-01  2019-01-14\n",
       "3    2017-05-09 14:20:04  2017-05-01  2017-01-01  2017-05-08\n",
       "4    2019-05-21 20:03:21  2019-05-01  2019-01-01  2019-05-20\n",
       "5    2017-06-14 11:37:10  2017-06-01  2017-01-01  2017-06-12\n",
       "6    2019-02-26 09:25:19  2019-02-01  2019-01-01  2019-02-25\n",
       "7    2017-11-15 01:28:23  2017-11-01  2017-01-01  2017-11-13\n",
       "8    2017-06-25 22:53:37  2017-06-01  2017-01-01  2017-06-19\n",
       "9    2019-01-13 08:28:44  2019-01-01  2019-01-01  2019-01-07"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hint:\n",
    "query_hint = \"\"\"\n",
    "SELECT  sales_transaction_date,\n",
    "\t\tDATE_TRUNC('month',sales_transaction_date)::DATE AS month,\n",
    "\t\tDATE_TRUNC('year',sales_transaction_date)::DATE AS year,\n",
    "\t\tDATE_TRUNC('week',sales_transaction_date)::DATE AS week\n",
    "FROM sales\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query_hint, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa2e82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bef8b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398ae143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b0c9b",
   "metadata": {},
   "source": [
    "\n",
    "## Part 4: Takeaways from the analysis\n",
    "\n",
    "Provide your thoughts about the analysis above by answering the following questions in the blank markdown cells provided below. No code should be run for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e7635",
   "metadata": {},
   "source": [
    "For each of the following questions, answer in as much preciseness and clarity that you can. Refer back to the tables and plots that you have created to back up your answers if necessary. Answer each question in the cell below. You are NOT to code anything for this section. This is for you to reflect on the analysis developed in response to Parts 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c37b2",
   "metadata": {},
   "source": [
    " 1. (Part 1) What are some potential hypotheses as to why the the most (least) popular products have the most (least) unit sales?  Describe how you would test your hypotheses in further analysis.  Do not conduct any additional analyses or write any more queries, just describe in words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4f0c3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68b5e379",
   "metadata": {},
   "source": [
    "2. (Part 2): How would you characterize the historical performance of the products visualized in Part 2 (e.g. is growth linear, exponential, constant, or etc.)? Are there major differences across the product types? Describe some of the trends in relative performance over time for the products.  Be specific and cite specific elements of the visualization created in Part 2 to support your claims.  Specify any additional factors you would want to consider that would influence your performance assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf8038",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2dc1d0a",
   "metadata": {},
   "source": [
    "3. (Part 3): How would you characterize the weekly sales by product type? Comment on seasonality and any unusual features. How does this compare to the sales targets? Is there seasonality in when we exceed the target? What are some potential hypotheses for what you have described?  Describe how you would test your hypotheses in further analysis.  Do not conduct any additional analyses or write any more queries, just describe in words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cd758",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
